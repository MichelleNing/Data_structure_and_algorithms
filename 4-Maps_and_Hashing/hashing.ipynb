{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashing\n",
    "\n",
    "## Introduction to Hashing\n",
    "\n",
    "Using a data structure that employs a hash function, allows you to do look-ups in constant time.\n",
    "\n",
    "## Hash Function\n",
    "\n",
    "The purpose of a hash function is to transform some value into one that can be stored and retrieved easily. You give it some value, it converts the value based on some formula and spits out a coded version of that value that's often the index in an array.\n",
    "\n",
    "## Collision \n",
    "\n",
    "There are time when a hash function will spit out the same hash value for two different inputs. This situation is termed a collision.\n",
    "\n",
    "There are two main ways to fix a collision.\n",
    "\n",
    "1 - change the value in your hash function, or to change the hash function completely. \n",
    "\n",
    "2- keep the hash functio and change the structure of your array. Insead of storing one hash value in each slot, you can store some type of lists that contains all values hashed at that spot. These lists are generally called buckets in this context.\n",
    "\n",
    "Rather than storing one value in each slot, you can store nultiple values or a collection in each bucket. For example, user can maintain constant time look up but by using a bigger number in your hash funciton, you're going to require a lot more space to store your values.  Example: \" x% 1,000,000 \" -- Efficiency : O(1) \n",
    "\n",
    "Also, if you do this reactively and change the value in your hash function, every time you have a collision, moving all of your data to a new array is going to definitely increase the complexity in terms of both size and time. With the bucket approach, you still need to iterate through some collections, through a shorter one, every time you're looking for something. Hash functions have a constant lookup time in the average case, but because of the bucket system, you could end up storing every value in one bucket and you're still essentially just iterating through a list. In that worse case, this actually turns into efficiency O(n).\n",
    "\n",
    "When done well, hashing is really fast and can save you a ton of time, but all of these things are very real concerns. There 's no one perfect way to design a hash function. Person need to consider all of these things and buid a system that makes the most sense for your data and your limitations. Often, we'll have to choose between making a hash function that spreads out your values nicely but uses a lot of space and one that uses less buckets but might have to do some searching within each bucket. Ideally, you would have one to three elements stored in each bucket. So can design a hash function with that in mind.\n",
    "\n",
    "\n",
    "Also can do something creative like using a second hash function inside of a large bucket to split up those elements even more. That would work particularly well if you know you're going to have well spread out dat abut end up having a few really large buckets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Factor\n",
    "\n",
    "When we're talking about hash tables, we can define a \"load factor\":\n",
    "\n",
    "Load Factor = Number of Entries / Number of Buckets\n",
    "\n",
    "The purpose of a load factor is to give us a sense of how \"full\" a hash table is. For example, if we're trying to store 10 values in a hash table with 1000 buckets, the load factor would be 0.01, and the majority of buckets in the table will be empty. We end up wasting memory by having so many empty buckets, so we may want to rehash, or come up with a new hash function with less buckets. We can use our load factor as an indicator for when to rehash—as the load factor approaches 0, the more empty, or sparse, our hash table is. \n",
    "On the flip side, the closer our load factor is to 1 (meaning the number of values equals the number of buckets), the better it would be for us to rehash and add more buckets. Any table with a load value greater than 1 is guaranteed to have collisions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practice for Load Factor\n",
    "\n",
    "One of your coworkers comes to you with a hash function that divides a group of values by 100, and uses the remainder as a key. The values are 100 unmbers that are all nultiples of 5.\n",
    "\n",
    "**Question:** \n",
    "\n",
    "What is the load factor?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "For the load factor, you should divide the number of values by the number of buckets. There are 100 values, as stated in the question, and 100 buckets (0 to 99). Thus, 100/100 = 1\n",
    "\n",
    "He thinks it's a little slow - what number would you recommend his function to divide by ranther than 100 to speed it up?\n",
    "\n",
    "A - 87    B - 107   C - 125   D - 1001\n",
    "\n",
    "**Answer:**  B\n",
    "\n",
    "The answer to the second part is 107. The other values all had something wrong with them:\n",
    "125 is also a multiple of 5. Dividing a bunch of multiples of 5 by another multiple of 5 will cause a lot of collisions. Here's an example, where 10 is used as the divisor:\n",
    "5 % 10 = 5\n",
    "10 % 10 = 0 \n",
    "15 % 10 = 5 \n",
    "20 % 10 = 0\n",
    "\n",
    "87 is better than 125, but because it's less than 100 it'll still have collisions.\n",
    "1001 is good, but it'll create a ton of leftover buckets and waste a lot of memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash Maps\n",
    "\n",
    "It's a intersection of two very important topics, maps and hashing.\n",
    "\n",
    "Hash maps are one of the main places you'll see hash function show up. In the previous example we were just using a hash function to find a place to store keys. However, maps have keys and values. The keys can be used as inputs to a hash function, store the key value pair in the bucket of the hash value produced by the function. \n",
    "\n",
    "Again sice you know the keys in a map are unique since they belong t oa set, a hash function could be used to give them each their own unique buckets. You can aso design a hash functio to allow for collisions. \n",
    "\n",
    "Hash maps are very useful to integerate into algorithms. Constant time lookups can really speed up your code. Keep in mind always think if it'll work first when thinking through data structures. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Keys\n",
    "\n",
    "The real beauty of the system is that you can use it with string keys too. You just need to come up with some hash function that converts letters into numbers. Individual letters can be pretty easily converted into ASCII values and many languages already have functions built in that do that. We can combine the ASCII values with a formula to get a unique hash for each letter.\n",
    "\n",
    "So what should our hash function look like? \n",
    "\n",
    "Again, there are some trade-offs here. Do we want every word in it's own bucket? Are you okay with collisions but want a relatively simple hash function? \n",
    "\n",
    "If you have 30 or less words, you can probably just use the ASCII value for the first letter of a string as a hash value. The standard hash code function for string keys in Java a large hash table over having any collisions. \n",
    "\n",
    "The formula looks something like this:\n",
    "\n",
    "s[0]*31^(n-1) + s[1]*31^(n-2) + ... + s[n-1]\n",
    "\n",
    "Foe example, let's say, we're going to hash the ord UDACITY and we're starting with the first two letters of the string, UD.\n",
    "\n",
    "U = 85, D = 68\n",
    "\n",
    "(85 x 31^1) + 68 = 2703\n",
    "\n",
    "By nultiplying the ASCII value for each letter by a power of some number, ilke 31, we can guarantee that every number representation or hash value will be unique to that string. A hash function like that would be great for a dictionary where we need unique buckets for each srting. \n",
    "\n",
    "Hwever strings with just three or four letters already have huge hash values. The **tradeoff** is really important here. As long as you have the space for it, a unique hash value can be really useful. \n",
    "\n",
    "Lastly, why is the number 31 used here?\n",
    "\n",
    "The earliest hash functions took advantage of some properties of the number 31 and research showed that it was a great choice for this kind of string hashing. However, now there are more complex hash functions that have been discovered. So 31 is more of a convention than the best value for every situation. Remember that designing a solutoin for your keys is the most important thing. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice\n",
    "\n",
    "Write your own hash table and hash function that uses string keys. Your table will store strings in buckets by their first two letters, according to the formula below:\n",
    "\n",
    "Hash Value = (ASCII Value of First Letter * 100) + ASCII Value of Second Letter \n",
    "\n",
    "You can assume that the string will have at least two letters, and the first two characters are uppercase letters (ASCII values from 65 to 90). You can use the Python function ord() to get the ASCII value of a letter, and chr() to get the letter associated with an ASCII value. \n",
    "\n",
    "create a HashTable class, methods to store and lookup values, and a helper function to calculate a hash value given a string. You cannot use a Python dictionary—only lists! And remember to store lists at each bucket, and not just the string itself. For example, you can store \"UDACITY\" at index 8568 as [\"UDACITY\"].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Write a HashTable class that stores strings in a hash table, where keys are calculated using the first two letters of the string.\"\"\"\n",
    "\n",
    "class HashTable(object):\n",
    "    def __init__(self):\n",
    "        self.table = [None]*10000\n",
    "\n",
    "    def store(self, string):\n",
    "        hv = self.calculate_hash_value(string)\n",
    "        if hv != -1:\n",
    "            if self.table[hv] != None:\n",
    "                self.table[hv].append(string)\n",
    "            else:\n",
    "                self.table[hv] = [string]\n",
    "\n",
    "    def lookup(self, string):\n",
    "        hv = self.calculate_hash_value(string)\n",
    "        if hv != -1:\n",
    "            if self.table[hv] != None:\n",
    "                if string in self.table[hv]:\n",
    "                    return hv\n",
    "        return -1\n",
    "\n",
    "    def calculate_hash_value(self, string):\n",
    "        value = ord(string[0])*100 + ord(string[1])\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8568\n",
      "-1\n",
      "8568\n",
      "8568\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "hash_table = HashTable()\n",
    "\n",
    "# Test calculate_hash_value\n",
    "# Should be 8568\n",
    "print(hash_table.calculate_hash_value('UDACITY'))\n",
    "\n",
    "# Test lookup edge case\n",
    "# Should be -1\n",
    "print(hash_table.lookup('UDACITY'))\n",
    "\n",
    "# Test store\n",
    "hash_table.store('UDACITY')\n",
    "# Should be 8568\n",
    "print(hash_table.lookup('UDACITY'))\n",
    "\n",
    "# Test store edge case\n",
    "hash_table.store('UDACIOUS')\n",
    "# Should be 8568\n",
    "print(hash_table.lookup('UDACIOUS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
